{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Pontificia Universidad Católica de Chile <br>\n","Departamento de Ciencia de la Computación <br>\n","IIC2433 - Minería de Datos\n","<br>\n","\n","<center>\n","    <h2> Tarea 2 </h2>\n","    <h1> Ham o spam  </h1>\n","    <p>\n","        Profesor Marcelo Mendoza<br>\n","        Segundo Semestre 2022<br>    \n","        Fecha de entrega: Viernes 23 de septiembre 22.00 horas\n","    </p>\n","    <br>\n","</center>\n","\n","<br>\n","\n","---"],"metadata":{"id":"YnDiLwUdS1Gu"}},{"cell_type":"markdown","source":["## Indicaciones\n","\n","Deberás entregar **SOLO** el archivo .ipynb en el buzón respectivo en canvas. \n","\n","**IMPORTANTE**: \n","- Se te dará puntaje tanto por código como por la manera en la que respondas las preguntas planteadas. Es decir, si tienes un código perfecto pero este no es explicado o no se responden preguntas asociadas a este, no se tendrá el puntaje completo.\n","- El notebook debe tener todas las celdas de código ejecutadas. Cualquier notebook que no las tenga no podrá ser corregido.\n","- El carácter de esta tarea es **INDIVIDUAL**. Cualquier instancia de copia resultará en un 1,1 como nota de curso.\n"],"metadata":{"id":"hXr7-famVI0x"}},{"cell_type":"markdown","source":["Utilizaremos una base de datos ubicada en Kaggle https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset que puedes encontrar igualmente en canvas como csv para descargar."],"metadata":{"id":"HEM29b-HVfIi"}},{"cell_type":"markdown","source":["## Introducción\n","\n","Nadie es inmune a recibir mensajes de Movistar o Entel ofreciéndonos planes. Abrir un mensaje para encontrarse con una hermosa sorpresa: es spam. \n","\n","Este es un problema a nivel mundial, tanto así que se han armado bases de datos con diferentes mensajes de texto recibidos por persona y si son considerados como spam o no (si no son spam se refiere a los mensajes como ham).\n","\n","Utilizando la vectorización de frases y clusterizando estas, deberás predecir si esta es o no spam. Además, deberás obtener los índices de calidad de los clusters."],"metadata":{"id":"ATIl8_5SZqH1"}},{"cell_type":"markdown","source":["## 0. Setup"],"metadata":{"id":"HanOLeY9fjFV"}},{"cell_type":"code","source":["from IPython.display import clear_output\n","\n","!pip3 uninstall spacy\n","!pip3 install spacy\n","\n","!spacy download en_core_web_lg\n","clear_output()\n","print('Ahora debes reiniciar el entorno de ejecución y ejecutar a partir de la siguiente celda')"],"metadata":{"id":"IResCwZ4gp8H","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663950881315,"user_tz":180,"elapsed":92541,"user":{"displayName":"FRANCISCO HORTAL","userId":"12015705806958710339"}},"outputId":"59c30195-9640-4493-fdd3-ccb4857877b0"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Ahora debes reiniciar el entorno de ejecución y ejecutar a partir de la siguiente celda\n"]}]},{"cell_type":"markdown","source":["## 1. Importar librerías y descargar dataset\n","En esta tarea trabajaremos con la librería `spacy` y el pipeline `en_core_web_lg` el cual pesa más de 500 MB y contiene un vocabulario en inglés de más de medio millón de palabras. Cada una de estas palabras es representable a partir de un vector de 300 dimensiones que nos ayudarán en la tarea. Revisa la [documentación](https://spacy.io/api) documentación de la librería para saber más."],"metadata":{"id":"6p4Ad0YDg0iH"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from collections import defaultdict\n","import spacy\n","\n","nlp = spacy.load(\"en_core_web_lg\")"],"metadata":{"id":"RPg3sNQOVH_5","executionInfo":{"status":"ok","timestamp":1663962584385,"user_tz":180,"elapsed":5771,"user":{"displayName":"FRANCISCO HORTAL","userId":"12015705806958710339"}}},"execution_count":193,"outputs":[]},{"cell_type":"markdown","source":["### Leer dataset"],"metadata":{"id":"B25-rStYiGjf"}},{"cell_type":"code","execution_count":194,"metadata":{"id":"MIX2mob7S0HQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663962586594,"user_tz":180,"elapsed":2218,"user":{"displayName":"FRANCISCO HORTAL","userId":"12015705806958710339"}},"outputId":"9bcee93b-517a-46fa-e196-f04d2f823531"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/gdrive')"]},{"cell_type":"code","source":["url = '/gdrive/My Drive/Colab Notebooks/Minería de Datos/Tareas/T2/spam.csv'\n","df = pd.read_csv(url, index_col=0, encoding=\"ISO-8859-1\")\n","df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":455},"id":"jO_3L7xSMTXz","executionInfo":{"status":"ok","timestamp":1663962586596,"user_tz":180,"elapsed":30,"user":{"displayName":"FRANCISCO HORTAL","userId":"12015705806958710339"}},"outputId":"0a050750-f11d-4382-9919-dc2dfeb79faf"},"execution_count":195,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                     v2 Unnamed: 2 Unnamed: 3  \\\n","v1                                                                              \n","ham   Go until jurong point, crazy.. Available only ...        NaN        NaN   \n","ham                       Ok lar... Joking wif u oni...        NaN        NaN   \n","spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN        NaN   \n","ham   U dun say so early hor... U c already then say...        NaN        NaN   \n","ham   Nah I don't think he goes to usf, he lives aro...        NaN        NaN   \n","...                                                 ...        ...        ...   \n","spam  This is the 2nd time we have tried 2 contact u...        NaN        NaN   \n","ham               Will Ì_ b going to esplanade fr home?        NaN        NaN   \n","ham   Pity, * was in mood for that. So...any other s...        NaN        NaN   \n","ham   The guy did some bitching but I acted like i'd...        NaN        NaN   \n","ham                          Rofl. Its true to its name        NaN        NaN   \n","\n","     Unnamed: 4  \n","v1               \n","ham         NaN  \n","ham         NaN  \n","spam        NaN  \n","ham         NaN  \n","ham         NaN  \n","...         ...  \n","spam        NaN  \n","ham         NaN  \n","ham         NaN  \n","ham         NaN  \n","ham         NaN  \n","\n","[5572 rows x 4 columns]"],"text/html":["\n","  <div id=\"df-45682bbc-e490-4b51-9b35-c005716d2426\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>v2</th>\n","      <th>Unnamed: 2</th>\n","      <th>Unnamed: 3</th>\n","      <th>Unnamed: 4</th>\n","    </tr>\n","    <tr>\n","      <th>v1</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>ham</th>\n","      <td>Go until jurong point, crazy.. Available only ...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>ham</th>\n","      <td>Ok lar... Joking wif u oni...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>spam</th>\n","      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>ham</th>\n","      <td>U dun say so early hor... U c already then say...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>ham</th>\n","      <td>Nah I don't think he goes to usf, he lives aro...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>spam</th>\n","      <td>This is the 2nd time we have tried 2 contact u...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>ham</th>\n","      <td>Will Ì_ b going to esplanade fr home?</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>ham</th>\n","      <td>Pity, * was in mood for that. So...any other s...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>ham</th>\n","      <td>The guy did some bitching but I acted like i'd...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>ham</th>\n","      <td>Rofl. Its true to its name</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5572 rows × 4 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-45682bbc-e490-4b51-9b35-c005716d2426')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-45682bbc-e490-4b51-9b35-c005716d2426 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-45682bbc-e490-4b51-9b35-c005716d2426');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":195}]},{"cell_type":"markdown","source":["## 2. Procesamiento de los datos (1 punto)"],"metadata":{"id":"HTPNejOsifeV"}},{"cell_type":"markdown","source":["### 2.1 Eliminación de datos\n","Solamente analizaremos las columnas de si es o no spam y cuál es el mensaje. Elimina las columnas restantes y preprocesa las filas eliminando los valores nulos."],"metadata":{"id":"1q04il_DkYTx"}},{"cell_type":"code","source":["df = df.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1)\n","df = df.dropna()\n","df.head(5)"],"metadata":{"id":"JydU6M3ekp7U","colab":{"base_uri":"https://localhost:8080/","height":237},"executionInfo":{"status":"ok","timestamp":1663962586599,"user_tz":180,"elapsed":28,"user":{"displayName":"FRANCISCO HORTAL","userId":"12015705806958710339"}},"outputId":"fdeb2555-5492-45e1-bb82-a95f743fa5ed"},"execution_count":196,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                     v2\n","v1                                                     \n","ham   Go until jurong point, crazy.. Available only ...\n","ham                       Ok lar... Joking wif u oni...\n","spam  Free entry in 2 a wkly comp to win FA Cup fina...\n","ham   U dun say so early hor... U c already then say...\n","ham   Nah I don't think he goes to usf, he lives aro..."],"text/html":["\n","  <div id=\"df-c96a7158-1bcb-4f0c-a064-2540e18541f0\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>v2</th>\n","    </tr>\n","    <tr>\n","      <th>v1</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>ham</th>\n","      <td>Go until jurong point, crazy.. Available only ...</td>\n","    </tr>\n","    <tr>\n","      <th>ham</th>\n","      <td>Ok lar... Joking wif u oni...</td>\n","    </tr>\n","    <tr>\n","      <th>spam</th>\n","      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n","    </tr>\n","    <tr>\n","      <th>ham</th>\n","      <td>U dun say so early hor... U c already then say...</td>\n","    </tr>\n","    <tr>\n","      <th>ham</th>\n","      <td>Nah I don't think he goes to usf, he lives aro...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c96a7158-1bcb-4f0c-a064-2540e18541f0')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c96a7158-1bcb-4f0c-a064-2540e18541f0 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c96a7158-1bcb-4f0c-a064-2540e18541f0');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":196}]},{"cell_type":"markdown","source":["### 2.2 Preprocesamiento de oraciones\n","\n","Acá te damos el código para preprocesar un texto."],"metadata":{"id":"JRc8KlOrKWya"}},{"cell_type":"code","source":["import string\n","\n","all_stopwords = nlp.Defaults.stop_words\n","\n","def remove_punctuation(text):\n","  text = [token for token in text if not token.is_punct]\n","  return text\n","\n","def remove_stopwords(words):\n","  words = [word for word in words if not word in all_stopwords]\n","  return words\n","\n","def lemmatize(words):\n","  words = [word.lemma_ for word in words]\n","  return words\n","\n","def remove_non_alpha(words):\n","  words = [word for word in words if word.isalpha()]\n","  return words\n","\n","def lower(words):\n","  words = [word.lower() for word in words]\n","  return words\n","\n","def min_len(words, length=3):\n","  words = [word for word in words if len(word)>=length]\n","  return words\n","\n","def preprocess(text):\n","\n","  doc = nlp(text)\n","  tokens = remove_punctuation(doc)\n","  tokens = remove_stopwords(tokens)\n","  tokens = lemmatize(tokens)\n","  tokens = remove_non_alpha(tokens)\n","  tokens = lower(tokens)\n","  tokens = min_len(tokens, length=3)\n","\n","  return ' '.join(tokens).strip()\n","\n","# Este es un ejemplo para que veas si tu preprocesamiento funcionó.\n","new_text = preprocess(\"This is the 2nd time we have tried 2 contact...\")\n","new_text"],"metadata":{"id":"nrEFtXFTlLHY","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1663962586602,"user_tz":180,"elapsed":29,"user":{"displayName":"FRANCISCO HORTAL","userId":"12015705806958710339"}},"outputId":"f55bf318-e058-4f74-c19d-ebab4225f4cd"},"execution_count":197,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'this the time have try contact'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":197}]},{"cell_type":"markdown","source":["Preprocesa todos los mensajes utilizando el método preprocess y guárdalos en un dataframe."],"metadata":{"id":"4aN3CB3ijwlB"}},{"cell_type":"code","source":["df_p = df\n","df_p['v2'] = df['v2'].apply(func=preprocess)\n","\n","df_p"],"metadata":{"id":"8R2tnE1PdxCE","colab":{"base_uri":"https://localhost:8080/","height":455},"executionInfo":{"status":"ok","timestamp":1663962624615,"user_tz":180,"elapsed":38041,"user":{"displayName":"FRANCISCO HORTAL","userId":"12015705806958710339"}},"outputId":"0dd84fbf-ea09-4ae6-e66f-32c73cb54901"},"execution_count":198,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                     v2\n","v1                                                     \n","ham   until jurong point crazy available only bugis ...\n","ham                                    lar joke wif oni\n","spam  free entry wkly comp win cup final tkts may te...\n","ham                  dun say early hor already then say\n","ham           nah not think usf live around here though\n","...                                                 ...\n","spam  this the time have try contact have win the po...\n","ham                                 will esplanade home\n","ham             pity mood for that any other suggestion\n","ham   the guy some bitch but act like would interest...\n","ham                              rofl its true its name\n","\n","[5572 rows x 1 columns]"],"text/html":["\n","  <div id=\"df-5e9726b8-6850-4cdc-a5ba-151f173c75d0\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>v2</th>\n","    </tr>\n","    <tr>\n","      <th>v1</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>ham</th>\n","      <td>until jurong point crazy available only bugis ...</td>\n","    </tr>\n","    <tr>\n","      <th>ham</th>\n","      <td>lar joke wif oni</td>\n","    </tr>\n","    <tr>\n","      <th>spam</th>\n","      <td>free entry wkly comp win cup final tkts may te...</td>\n","    </tr>\n","    <tr>\n","      <th>ham</th>\n","      <td>dun say early hor already then say</td>\n","    </tr>\n","    <tr>\n","      <th>ham</th>\n","      <td>nah not think usf live around here though</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>spam</th>\n","      <td>this the time have try contact have win the po...</td>\n","    </tr>\n","    <tr>\n","      <th>ham</th>\n","      <td>will esplanade home</td>\n","    </tr>\n","    <tr>\n","      <th>ham</th>\n","      <td>pity mood for that any other suggestion</td>\n","    </tr>\n","    <tr>\n","      <th>ham</th>\n","      <td>the guy some bitch but act like would interest...</td>\n","    </tr>\n","    <tr>\n","      <th>ham</th>\n","      <td>rofl its true its name</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5572 rows × 1 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5e9726b8-6850-4cdc-a5ba-151f173c75d0')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-5e9726b8-6850-4cdc-a5ba-151f173c75d0 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-5e9726b8-6850-4cdc-a5ba-151f173c75d0');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":198}]},{"cell_type":"markdown","source":["### 2.3 Vectorizar oraciones\n","En esta tarea, el vector de una oración será el promedio de los vectores de cada una de las palabras que fueron preprocesadas de la oración. La función presentada a continuación vectoriza una oración a partir de los vectores de las palabras.\n","\n"],"metadata":{"id":"_wga_PgMmMmr"}},{"cell_type":"code","source":["def sentence_vector(text):\n","  text = nlp(text)\n","  vectores = []\n","  for t in text:\n","    t_vector = t.vector\n","    vectores.append(t_vector)\n","  return np.array(vectores).sum(axis=0)/len(vectores)"],"metadata":{"id":"z369fruNmVMF","executionInfo":{"status":"ok","timestamp":1663962624616,"user_tz":180,"elapsed":16,"user":{"displayName":"FRANCISCO HORTAL","userId":"12015705806958710339"}}},"execution_count":199,"outputs":[]},{"cell_type":"code","source":["df_p['v2'] = df['v2'].apply(func=sentence_vector)"],"metadata":{"id":"dQzjsoeZRCp_","executionInfo":{"status":"ok","timestamp":1663962653790,"user_tz":180,"elapsed":29186,"user":{"displayName":"FRANCISCO HORTAL","userId":"12015705806958710339"}}},"execution_count":200,"outputs":[]},{"cell_type":"markdown","source":["### 2.4. Obtener matriz de distancias\n"],"metadata":{"id":"6aUAuR0_g195"}},{"cell_type":"markdown","source":["Obtén una forma de calcular una matriz que por cada par distintos de oraciones contenga la distancia euclidiana y coseno entre los vectores que representan a cada una. \n","\n","Hint: el método pairwise_distances de sklearn realiza esta operación eficientemente y no genera problemas de RAM.\n","\n"],"metadata":{"id":"vbHlE8PjhKNg"}},{"cell_type":"markdown","source":["Creamos dos función a la cual se le pasen dos vectores y nos proporcione una matriz de distancias. Una se basa en el método euclideano y la otra por coseno"],"metadata":{"id":"abmOiAmSMd01"}},{"cell_type":"code","source":["from sklearn.metrics import pairwise_distances\n","def matriz_distancias_e(v1, v2):\n","  matriz = pairwise_distances(v1, v2, metric='euclidean')\n","  return np.array(matriz)\n","def matriz_distancias_c(v1, v2):\n","  matriz = pairwise_distances(v1, v2, metric='cosine')\n","  return np.array(matriz)"],"metadata":{"id":"fBSyhBgshK4o","executionInfo":{"status":"ok","timestamp":1663962653791,"user_tz":180,"elapsed":36,"user":{"displayName":"FRANCISCO HORTAL","userId":"12015705806958710339"}}},"execution_count":201,"outputs":[]},{"cell_type":"markdown","source":["Eliminamos datos nulos"],"metadata":{"id":"l-q4SXmMmmCg"}},{"cell_type":"code","source":["df_p = df_p.dropna()"],"metadata":{"id":"pB4saT2klHrc","executionInfo":{"status":"ok","timestamp":1663962653792,"user_tz":180,"elapsed":33,"user":{"displayName":"FRANCISCO HORTAL","userId":"12015705806958710339"}}},"execution_count":202,"outputs":[]},{"cell_type":"markdown","source":["Creamos na variable que contenga los vectores"],"metadata":{"id":"fHb91GrZmobH"}},{"cell_type":"code","source":["vectors = np.stack(df_p[\"v2\"].values)"],"metadata":{"id":"P0ksP2fVc9MY","executionInfo":{"status":"ok","timestamp":1663962653793,"user_tz":180,"elapsed":31,"user":{"displayName":"FRANCISCO HORTAL","userId":"12015705806958710339"}}},"execution_count":203,"outputs":[]},{"cell_type":"markdown","source":["Generamos una matriz de distancias euclideanas"],"metadata":{"id":"CxoLkYNZmss0"}},{"cell_type":"code","source":["m_e = matriz_distancias_e(vectors, vectors)\n","m_e"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T_dxEGclMcyT","executionInfo":{"status":"ok","timestamp":1663962654166,"user_tz":180,"elapsed":401,"user":{"displayName":"FRANCISCO HORTAL","userId":"12015705806958710339"}},"outputId":"07a82f38-7689-4877-de67-a48f3acf017d"},"execution_count":204,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 0.      , 22.287176, 21.584124, ..., 25.64222 , 17.197527,\n","        41.088566],\n","       [22.287176,  0.      , 29.280226, ..., 36.931423, 31.36411 ,\n","        45.26217 ],\n","       [21.584124, 29.280226,  0.      , ..., 29.595678, 25.300081,\n","        43.817024],\n","       ...,\n","       [25.64222 , 36.931423, 29.595678, ...,  0.      , 20.358713,\n","        42.429527],\n","       [17.197527, 31.36411 , 25.300081, ..., 20.358713,  0.      ,\n","        43.578625],\n","       [41.088566, 45.26217 , 43.817024, ..., 42.429527, 43.578625,\n","         0.      ]], dtype=float32)"]},"metadata":{},"execution_count":204}]},{"cell_type":"markdown","source":["Generamos una matriz con las distancias por coseno"],"metadata":{"id":"aw-xnnJVmyUB"}},{"cell_type":"code","source":["m_c = matriz_distancias_c(vectors, vectors)\n","m_c"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5622kTupmYvW","executionInfo":{"status":"ok","timestamp":1663962654544,"user_tz":180,"elapsed":380,"user":{"displayName":"FRANCISCO HORTAL","userId":"12015705806958710339"}},"outputId":"7242d253-ddcc-41ad-f04a-de386f519328"},"execution_count":205,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.        , 0.8346631 , 0.42814863, ..., 0.3057986 , 0.15957665,\n","        0.64997876],\n","       [0.8346631 , 0.        , 1.0922576 , ..., 0.9585984 , 0.8705199 ,\n","        0.99595284],\n","       [0.42814863, 1.0922576 , 0.        , ..., 0.4369179 , 0.40039504,\n","        0.7226788 ],\n","       ...,\n","       [0.3057986 , 0.9585984 , 0.4369179 , ..., 0.        , 0.18286031,\n","        0.5653542 ],\n","       [0.15957665, 0.8705199 , 0.40039504, ..., 0.18286031, 0.        ,\n","        0.6536323 ],\n","       [0.64997876, 0.99595284, 0.7226788 , ..., 0.5653542 , 0.6536323 ,\n","        0.        ]], dtype=float32)"]},"metadata":{},"execution_count":205}]},{"cell_type":"code","source":["m_e.shape[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LGEu8PMuv4B4","executionInfo":{"status":"ok","timestamp":1663962654545,"user_tz":180,"elapsed":12,"user":{"displayName":"FRANCISCO HORTAL","userId":"12015705806958710339"}},"outputId":"cac6ab3b-93f3-4e58-bc7f-ebaa7c0da0d1"},"execution_count":206,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5537"]},"metadata":{},"execution_count":206}]},{"cell_type":"markdown","source":["## 3. Clase AgglomerativeClustering (3 puntos)\n","\n","Esta clase debe implemetar el algoritmo de clustering jerárquico aglomerativo. Para esto **debes** programar los siguientes métodos:\n","\n","\n","### **\\_\\_init\\_\\_**\n","Inicializa el algoritmo a partir de: la matriz `X` de los mensajes y la matriz de distancias. Considera además todas las variables que necesites a lo largo de la ejecución de tu algoritmo, se recomienda como mínimo:\n","*   Un contador que indique el nivel actual de aglomeración.\n","*   Un diccionario o lista que almacene los clusters en cada nivel de aglomeración. Inicialmente, en el nivel 0, existe un *cluster* por cada mensaje de `X`.\n","*   La matriz de distancia entre los *clusters* donde el elemento `matriz[id1][id2]` corresponde a la distancia entre los clusters con identificadores `id1` e `id2` respectivamente. \n","*   Una copia de la matriz original X.\n","\n","\n","### **clusterize**\n","Ejecuta el método next_level hasta que solo existan dos *clusters*.\n","\n","##### **next_level**\n","Equivale a realizar un nivel de aglomeración del algoritmo. A modo general deben:\n","1.   Obtener el par de *clusters* con menor distancia a partir de la matriz de distancias obtenida en 3.\n","2.   Unir ambos *clusters*.\n","3.   Guardar el nuevo conjunto de *clusters* correspondientes al nivel actual de aglomeración.\n","4.   Actualizar la matriz de distancias según el nuevo conjunto de *clusters*.\n","\n","##### **update_matrix**\n","Actualiza la matriz de distancias dado un nuevo *cluster*. La distancia entre *clusters* debe poder calcularse según los siguientes enlaces (`linkage`) vistos en clases:\n","1.   **centroid**: distancia entre medias.\n","2.   **single**: simple.\n","\n","<br>\n","\n","---\n","\n","**NOTA**: puedes entregarle los argumentos que quieras a estos métodos y tambien crear otros métodos que consideres pertinentes."],"metadata":{"id":"-NGGrYDXe_Vb"}},{"cell_type":"markdown","source":["En base a lo visto en clases deberás implementar el algoritmo de clustering aglomerativo para agrupar los datos previamente preprocesados."],"metadata":{"id":"zhMaokeoTulC"}},{"cell_type":"markdown","source":["Se utiliza esto como inspiración: https://github.com/mithunjmistry/hierarchical-clustering/blob/master/HierarchicalClustering.ipynb"],"metadata":{"id":"SX8SUAJ-0Lja"}},{"cell_type":"code","source":["class AgglomerativeClustering:\n","\n","  def __init__(self, X, linkage=\"centroid\", distance=\"Euclidean\"):\n","    # Vectores de cada pais. \n","    self.X = X.copy()\n","    # Linkage.\n","    self.linkage = linkage\n","    # Métrica de distancia.\n","    self.distance = distance\n","\n","    # Matriz de distancias (obtén la matriz de distancias inicial)\n","    self.matrix = self.get_distance(X, X)\n","\n","    # Copia de la matriz de distancias original.\n","    self.original_matrix = self.matrix.copy()\n","\n","    # Contador nivel actual aglomeración\n","    self.nivel_aglomeracion = 0\n","\n","    # Diccionario que guarda los clusters en el respectivo nivel\n","    self.dict_na = {}\n","\n","  def clusterize(self):\n","    # Inicializamos un dataframe que contendrá las posiciones de los clusters en la matriz.\n","    df = pd.DataFrame(data=np.ones(self.X.shape[0])*np.inf)\n","    for i in range(0,self.matrix.shape[0]):\n","      # i será nuestro contador de aglomeraciones\n","      self.nivel_aglomeracion = i\n","      # iteramos para obtener los clusters\n","      cluster_matrix = self.next_level(df)\n","\n","    return self.dict_na, cluster_matrix\n","\n","  def next_level(self, df):\n","    \n","    # Se obtiene el par de clusters con menor distancia de la matriz de distancias.\n","            ij_min = np.unravel_index(self.matrix.argmin(), self.matrix.shape) \n","            #np.unravel_index nos da la posición de el valor mínimo\n","            # Ahora completaremos el dataframe combinando los dos puntos y clusters\n","            if self.nivel_aglomeracion == 0:\n","                df.iloc[ij_min[0]] = 0\n","                df.iloc[ij_min[1]] = 0\n","            else:\n","                try:\n","                    a = int(df.iloc[ij_min[0]])\n","                except:\n","                    df.iloc[ij_min[0]] = self.nivel_aglomeracion\n","                    a = self.nivel_aglomeracion\n","                try:\n","                    b = int(df.iloc[ij_min[1]])\n","                except:\n","                    df.iloc[ij_min[1]] = self.nivel_aglomeracion\n","                    b = self.nivel_aglomeracion\n","                df[(df[0]==a) | (df[0]==b)] = self.nivel_aglomeracion\n","            # Almacenamos el nivel y los clusters que existen\n","            self.dict_na[self.nivel_aglomeracion] = df[0].unique()     \n","\n","            #De esta manera si combinamos dos puntos, estos quedarán anotados en el diccionario con su respectivo cluster.\n","            for j in range(0, ij_min[0]):\n","                #Ignoramos la diagonal transformando 0 a inf\n","                if np.isfinite(self.matrix[ij_min[0]][j]) and np.isfinite(self.matrix[ij_min[1]][j]):\n","                    #Actualizamos la matriz\n","                    self.update_matrix(ij_min, j)\n","            # Para evitar futuras combinaciones hacemos todo infinito\n","            self.matrix[ij_min[0]] = np.inf\n","\n","            return df[0]\n","        \n","\n","  \n","  def update_matrix(self, cluster, j):\n","\n","    if self.linkage == \"centroid\":\n","      # Tomamos el promedio\n","      self.matrix[cluster[1]][j] = (self.matrix[cluster[0]][j] + self.matrix[cluster[1]][j])/2.0          \n","      return self.matrix[cluster[1]][j]\n","\n","    elif self.linkage == \"single\":\n","      # Tomamos el mínimo\n","      self.matrix[cluster[1]][j] = min(self.matrix[cluster[0]][j], self.matrix[cluster[1]][j])\n","      return self.matrix[cluster[1]][j]\n","\n","  def get_distance(self, vector1, vector2):\n","    if self.distance == \"Euclidean\": \n","      # Obtenemos la distancia\n","      matrix = matriz_distancias_e(vector1, vector2)\n","      # Como es simetrica, solo dejamos el triangulo de abajo\n","      matrix = np.tril(matrix)\n","      # Reemplazamos os 0 por inf, lo que hará más fácil sacar mínimos\n","      matrix[matrix == 0] = np.inf\n","      return matrix\n","    \n","    elif self.distance == \"Cosine\":\n","      matrix = matriz_distancias_c(vector1, vector2)\n","      # Como es simetrica, solo dejamos el triangulo de abajo\n","      matrix = np.tril(matrix)\n","      # Reemplazamos os 0 por inf, lo que hará más fácil sacar mínimos\n","      matrix[matrix == 0] = np.inf\n","      return matrix"],"metadata":{"id":"nMvVAAalUpYb","executionInfo":{"status":"ok","timestamp":1663962654546,"user_tz":180,"elapsed":7,"user":{"displayName":"FRANCISCO HORTAL","userId":"12015705806958710339"}}},"execution_count":207,"outputs":[]},{"cell_type":"markdown","source":["Utiliza la clase para realizar la aglomeración con los datos preprocesados de spam:"],"metadata":{"id":"-6ALTMRzXWMB"}},{"cell_type":"code","source":["clustering = AgglomerativeClustering(vectors)\n","d, target = clustering.clusterize()"],"metadata":{"id":"HuhX_nSzXuUx","executionInfo":{"status":"ok","timestamp":1663962839424,"user_tz":180,"elapsed":184885,"user":{"displayName":"FRANCISCO HORTAL","userId":"12015705806958710339"}}},"execution_count":208,"outputs":[]},{"cell_type":"markdown","source":["d es un diccionario con los momentos de aglomeracion y los clusters. Target son los clusters al final de todo el proceso y en el último momento de clusterización."],"metadata":{"id":"kSRtTAnpJU3p"}},{"cell_type":"code","source":["for i in range(50):\n","  print(d[i])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eNrV5uBt_1VY","executionInfo":{"status":"ok","timestamp":1663962839426,"user_tz":180,"elapsed":33,"user":{"displayName":"FRANCISCO HORTAL","userId":"12015705806958710339"}},"outputId":"6db1db5c-db80-4dc6-d7e6-edae6a5f0dd4"},"execution_count":209,"outputs":[{"output_type":"stream","name":"stdout","text":["[inf  0.]\n","[inf  0.  1.]\n","[inf  0.  2.]\n","[inf  0.  3.]\n","[inf  0.  4.]\n","[inf  5.  0.  4.]\n","[inf  6.  0.  4.]\n","[inf  6.  0.  7.  4.]\n","[inf  6.  8.  0.  7.  4.]\n","[inf  6.  8.  0.  7.  9.  4.]\n","[inf  6.  8.  0.  7.  9. 10.  4.]\n","[inf  6.  8.  0.  7.  9. 10. 11.  4.]\n","[inf  6.  8. 12.  0.  7.  9. 10. 11.  4.]\n","[inf  6.  8. 12.  0.  7.  9. 13. 10. 11.  4.]\n","[inf 14.  6.  8. 12.  0.  7.  9. 13. 10. 11.  4.]\n","[inf 14.  6.  8. 12.  0.  7.  9. 13. 10. 15.  4.]\n","[inf 14.  6.  8. 12.  0.  7.  9. 13. 10. 15.  4. 16.]\n","[inf 14.  6.  8. 17. 12.  0.  7.  9. 13. 10. 15.  4. 16.]\n","[inf 14.  6.  8. 17. 12.  0.  7.  9. 13. 10. 15.  4. 16. 18.]\n","[inf 14.  6.  8. 19. 17. 12.  0.  7.  9. 13. 10. 15.  4. 16. 18.]\n","[inf 14.  6.  8. 20. 17. 12.  0.  7.  9. 13. 10. 15.  4. 16. 18.]\n","[inf 21. 14.  6.  8. 20. 17. 12.  0.  7.  9. 13. 10. 15.  4. 16. 18.]\n","[inf 21. 14.  6.  8. 20. 22. 17. 12.  0.  7.  9. 13. 10. 15.  4. 16. 18.]\n","[inf 23. 21. 14.  6.  8. 20. 22. 17. 12.  0.  7.  9. 13. 10. 15.  4. 16.\n"," 18.]\n","[inf 23. 21. 24. 14.  6.  8. 20. 22. 17. 12.  0.  7.  9. 13. 10. 15.  4.\n"," 16. 18.]\n","[inf 23. 25. 21. 24. 14.  6.  8. 20. 22. 17. 12.  0.  7.  9. 13. 10. 15.\n","  4. 16. 18.]\n","[inf 23. 25. 21. 24. 14. 26.  6.  8. 20. 22. 17. 12.  0.  7.  9. 13. 10.\n"," 15.  4. 16. 18.]\n","[inf 23. 25. 21. 24. 14. 26.  6.  8. 20. 22. 17. 12.  0.  7.  9. 13. 10.\n"," 27. 15.  4. 16. 18.]\n","[inf 23. 25. 21. 24. 14. 26.  6.  8. 20. 22. 28. 17. 12.  0.  7.  9. 13.\n"," 10. 27. 15.  4. 16. 18.]\n","[inf 23. 25. 21. 24. 14. 26.  6.  8. 20. 22. 28. 17. 12.  0.  7.  9. 13.\n"," 29. 10. 27. 15.  4. 16. 18.]\n","[inf 23. 25. 21. 24. 14. 26.  6.  8. 20. 22. 28. 17. 12.  0.  7.  9. 13.\n"," 29. 10. 27. 15.  4. 16. 30. 18.]\n","[inf 23. 25. 21. 24. 14. 26.  6.  8. 20. 22. 31. 17. 12.  0.  7.  9. 13.\n"," 29. 10. 27. 15.  4. 16. 30. 18.]\n","[inf 23. 25. 21. 24. 14. 26.  6.  8. 20. 22. 31. 17. 12.  0.  7.  9. 13.\n"," 32. 10. 27. 15.  4. 16. 30. 18.]\n","[inf 23. 25. 21. 24. 14. 26.  6.  8. 20. 22. 31. 17. 12.  0.  7.  9. 13.\n"," 33. 10. 27. 15.  4. 16. 30. 18.]\n","[inf 23. 25. 21. 24. 14. 26.  6.  8. 20. 22. 31. 17. 12.  0.  7.  9. 13.\n"," 33. 10. 27. 15. 34.  4. 16. 30. 18.]\n","[inf 23. 25. 21. 24. 14. 26.  6.  8. 20. 22. 31. 17. 12.  0. 35.  7.  9.\n"," 13. 33. 10. 27. 15. 34.  4. 16. 30. 18.]\n","[inf 23. 25. 21. 24. 14. 26.  6.  8. 20. 22. 36. 31. 17. 12.  0. 35.  7.\n","  9. 13. 33. 10. 27. 15. 34.  4. 16. 30. 18.]\n","[inf 23. 25. 21. 24. 14. 26.  6.  8. 20. 22. 36. 31. 17. 12.  0. 35.  7.\n","  9. 13. 37. 33. 10. 27. 15. 34.  4. 16. 30. 18.]\n","[inf 23. 25. 21. 24. 14. 26.  6.  8. 20. 22. 36. 31. 17. 12.  0. 35.  7.\n","  9. 13. 37. 33. 10. 27. 15. 38.  4. 16. 30. 18.]\n","[inf 23. 25. 21. 24. 14. 26.  6.  8. 20. 22. 36. 31. 17. 12.  0. 35.  7.\n","  9. 13. 37. 33. 10. 27. 15. 38.  4. 16. 30. 18. 39.]\n","[inf 23. 25. 21. 24. 14. 26.  6.  8. 20. 22. 36. 31. 17. 12.  0. 35.  7.\n","  9. 13. 37. 33. 10. 40. 27. 15. 38.  4. 16. 30. 18. 39.]\n","[inf 23. 25. 21. 24. 14. 26.  6.  8. 20. 22. 36. 31. 17. 12.  0. 41.  7.\n","  9. 13. 37. 33. 10. 40. 27. 15. 38.  4. 16. 30. 18. 39.]\n","[inf 23. 25. 21. 24. 14. 42.  6.  8. 20. 22. 36. 31. 17. 12.  0. 41.  7.\n","  9. 13. 37. 33. 10. 40. 27. 15. 38.  4. 16. 30. 18. 39.]\n","[inf 23. 25. 21. 24. 14. 42.  6.  8. 20. 22. 43. 36. 31. 17. 12.  0. 41.\n","  7.  9. 13. 37. 33. 10. 40. 27. 15. 38.  4. 16. 30. 18. 39.]\n","[inf 23. 25. 21. 24. 14. 42.  6.  8. 20. 22. 43. 36. 31. 17. 12.  0. 44.\n"," 41.  7.  9. 13. 37. 33. 10. 40. 27. 15. 38.  4. 16. 30. 18. 39.]\n","[inf 23. 25. 21. 24. 14. 42.  6.  8. 20. 22. 43. 36. 31. 17. 12.  0. 44.\n"," 41.  7.  9. 13. 37. 33. 10. 40. 27. 15. 38.  4. 16. 30. 18. 45.]\n","[inf 23. 25. 21. 24. 14. 42.  6.  8. 20. 22. 43. 36. 31. 17. 12.  0. 44.\n"," 41.  7.  9. 13. 46. 37. 33. 10. 40. 27. 15. 38.  4. 16. 30. 18. 45.]\n","[inf 23. 25. 21. 24. 14. 42.  6.  8. 20. 22. 47. 43. 36. 31. 17. 12.  0.\n"," 44. 41.  7.  9. 13. 46. 37. 33. 10. 40. 27. 15. 38.  4. 16. 30. 18. 45.]\n","[inf 23. 25. 21. 48. 14. 42.  6.  8. 20. 22. 47. 43. 36. 31. 17. 12.  0.\n"," 44. 41.  7.  9. 13. 46. 37. 33. 10. 40. 27. 15. 38.  4. 16. 30. 18. 45.]\n","[inf 23. 25. 21. 48. 14. 42.  6.  8. 20. 22. 47. 43. 36. 31. 17. 12.  0.\n"," 44. 41.  7.  9. 13. 46. 49. 33. 10. 40. 27. 15. 38.  4. 16. 30. 18. 45.]\n"]}]},{"cell_type":"markdown","source":["Podemos ver como se comienza con un solo cluster y luego mientras más iteraciones, más clusters"],"metadata":{"id":"9arNOcCUFc-x"}},{"cell_type":"code","source":["target"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bK8lZe0-_5jo","executionInfo":{"status":"ok","timestamp":1663962839428,"user_tz":180,"elapsed":23,"user":{"displayName":"FRANCISCO HORTAL","userId":"12015705806958710339"}},"outputId":"16c565af-94c3-4ba8-d618-231b8a0a3221"},"execution_count":210,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0       5536.0\n","1       5536.0\n","2       5536.0\n","3       5536.0\n","4       5536.0\n","         ...  \n","5532    5536.0\n","5533    5536.0\n","5534    5536.0\n","5535    5536.0\n","5536    5536.0\n","Name: 0, Length: 5537, dtype: float64"]},"metadata":{},"execution_count":210}]},{"cell_type":"markdown","source":["# 4. Comparación con distintos parámetros (1 punto)\n","\n","En esta parte deberás comparar distintas configuraciones de tu algoritmo de *clustering* y concluir cual de estas es la mejor.\n","\n","Una forma de comparar *clusters* es a partir de su *silhouette score*. Este mide cuán similar es un objeto a su propio *cluster* (cohesión) en comparación con otros *clusters* (separación). Completa el siguiente código utilizando la función `silhouette_score` de `sklearn.metrics`.\n","\n","NOTA: debes adaptar la estructura de clusters retornada por `AgglomerativeClustering` de tal forma que pueda ser utilizada como los `labels` que recibe `silhouette_score` ([documentación](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html))."],"metadata":{"id":"8HPYMJC5X9Vf"}},{"cell_type":"markdown","source":["Adaptaremos la clase para poder obtener los datos de labels para el  silhouette_score. Definiremos la cantidad de aglomeraciones previamente. Calcularemos 1000, ya que más que estas nos harán sumamente costoso computacionalmente el ejercicio y no darán un resultado relevante."],"metadata":{"id":"2XxOtjR1G-Ao"}},{"cell_type":"code","source":["class AgglomerativeClustering:\n","\n","  def __init__(self, X, linkage=\"centroid\", distance=\"Euclidean\", cutoff=1000):\n","    # Vectores de cada pais. \n","    self.X = X.copy()\n","    # Linkage.\n","    self.linkage = linkage\n","    # Métrica de distancia.\n","    self.distance = distance\n","\n","    # Matriz de distancias (obtén la matriz de distancias inicial)\n","    self.matrix = self.get_distance(X, X)\n","\n","    # Copia de la matriz de distancias original.\n","    self.original_matrix = self.matrix.copy()\n","\n","    # Contador nivel actual aglomeración\n","    self.nivel_aglomeracion = 0\n","\n","    # Diccionario que guarda los clusters en el respectivo nivel\n","    self.dict_na = {}\n","\n","    # Numero máximo de iteraciones\n","    self.cutoff = cutoff\n","\n","  def clusterize(self):\n","    # Inicializamos un dataframe que contendrá las posiciones de los clusters en la matriz.\n","    df = pd.DataFrame(data=np.ones(self.X.shape[0])*np.inf)\n","    for i in range(0,self.cutoff):\n","      # i será nuestro contador de aglomeraciones\n","      self.nivel_aglomeracion = i\n","      # iteramos para obtener los clusters\n","      cluster_matrix = self.next_level(df)\n","\n","    return self.dict_na, cluster_matrix\n","\n","  def next_level(self, df):\n","    \n","    # Se obtiene el par de clusters con menor distancia de la matriz de distancias.\n","            ij_min = np.unravel_index(self.matrix.argmin(), self.matrix.shape) \n","            #np.unravel_index nos da la posición de el valor mínimo\n","            # Ahora completaremos el dataframe combinando los dos puntos y clusters\n","            if self.nivel_aglomeracion == 0:\n","                df.iloc[ij_min[0]] = 0\n","                df.iloc[ij_min[1]] = 0\n","            else:\n","                try:\n","                    a = int(df.iloc[ij_min[0]])\n","                except:\n","                    df.iloc[ij_min[0]] = self.nivel_aglomeracion\n","                    a = self.nivel_aglomeracion\n","                try:\n","                    b = int(df.iloc[ij_min[1]])\n","                except:\n","                    df.iloc[ij_min[1]] = self.nivel_aglomeracion\n","                    b = self.nivel_aglomeracion\n","                df[(df[0]==a) | (df[0]==b)] = self.nivel_aglomeracion\n","            # Almacenamos el nivel y los clusters que existen\n","            self.dict_na[self.nivel_aglomeracion] = df[0].unique()     \n","\n","            #De esta manera si combinamos dos puntos, estos quedarán anotados en el diccionario con su respectivo cluster.\n","            for j in range(0, ij_min[0]):\n","                #Ignoramos la diagonal transformando 0 a inf\n","                if np.isfinite(self.matrix[ij_min[0]][j]) and np.isfinite(self.matrix[ij_min[1]][j]):\n","                    #Actualizamos la matriz\n","                    self.update_matrix(ij_min, j)\n","            # Para evitar futuras combinaciones hacemos todo infinito\n","            self.matrix[ij_min[0]] = np.inf\n","\n","            return df[0]\n","        \n","\n","  \n","  def update_matrix(self, cluster, j):\n","\n","    if self.linkage == \"centroid\":\n","      # Tomamos el promedio\n","      self.matrix[cluster[1]][j] = (self.matrix[cluster[0]][j] + self.matrix[cluster[1]][j])/2.0          \n","      return self.matrix[cluster[1]][j]\n","\n","    elif self.linkage == \"single\":\n","      # Tomamos el mínimo\n","      self.matrix[cluster[1]][j] = min(self.matrix[cluster[0]][j], self.matrix[cluster[1]][j])\n","      return self.matrix[cluster[1]][j]\n","\n","  def get_distance(self, vector1, vector2):\n","    if self.distance == \"Euclidean\": \n","      # Obtenemos la distancia\n","      matrix = matriz_distancias_e(vector1, vector2)\n","      # Como es simetrica, solo dejamos el triangulo de abajo\n","      matrix = np.tril(matrix)\n","      # Reemplazamos os 0 por inf, lo que hará más fácil sacar mínimos\n","      matrix[matrix == 0] = np.inf\n","      return matrix\n","    \n","    elif self.distance == \"Cosine\":\n","      matrix = matriz_distancias_c(vector1, vector2)\n","      # Como es simetrica, solo dejamos el triangulo de abajo\n","      matrix = np.tril(matrix)\n","      # Reemplazamos os 0 por inf, lo que hará más fácil sacar mínimos\n","      matrix[matrix == 0] = np.inf\n","      return matrix"],"metadata":{"id":"fKeWIVidSBQ9","executionInfo":{"status":"ok","timestamp":1663962839884,"user_tz":180,"elapsed":468,"user":{"displayName":"FRANCISCO HORTAL","userId":"12015705806958710339"}}},"execution_count":211,"outputs":[]},{"cell_type":"markdown","source":["Obtenemos las iteraciones con los clusters respectivos"],"metadata":{"id":"3fWQWF7iZ6Vw"}},{"cell_type":"code","source":["clustering = AgglomerativeClustering(vectors)\n","d, target = clustering.clusterize()"],"metadata":{"id":"RjpSYXz8aDVh","executionInfo":{"status":"ok","timestamp":1663962876886,"user_tz":180,"elapsed":37007,"user":{"displayName":"FRANCISCO HORTAL","userId":"12015705806958710339"}}},"execution_count":212,"outputs":[]},{"cell_type":"markdown","source":["Obtenemos una tabla con 1 para cuando el mensaje es ham y 0 cuando es spam"],"metadata":{"id":"W6ue-cytj5dR"}},{"cell_type":"code","source":["X = df_p.index\n","X = pd.get_dummies(X)"],"metadata":{"id":"BCm2wPbzanE-","executionInfo":{"status":"ok","timestamp":1663962876887,"user_tz":180,"elapsed":21,"user":{"displayName":"FRANCISCO HORTAL","userId":"12015705806958710339"}}},"execution_count":213,"outputs":[]},{"cell_type":"markdown","source":["Formateamos target para que entre bien en el algoritmo"],"metadata":{"id":"cPJ6fnS3cbIq"}},{"cell_type":"code","source":["labels = target.values\n","labels[labels==np.inf] = -1\n","labels = labels.astype(int)"],"metadata":{"id":"E2NltHLlaHcE","executionInfo":{"status":"ok","timestamp":1663962876888,"user_tz":180,"elapsed":21,"user":{"displayName":"FRANCISCO HORTAL","userId":"12015705806958710339"}}},"execution_count":214,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import silhouette_score\n","\n","def messages_silhouette_score(X, clusters):\n","  print('Silhouette score for 1000 is '+str(silhouette_score(X, clusters, metric='euclidean')))"],"metadata":{"id":"RD1tB3ZFYHLT","executionInfo":{"status":"ok","timestamp":1663962876889,"user_tz":180,"elapsed":21,"user":{"displayName":"FRANCISCO HORTAL","userId":"12015705806958710339"}}},"execution_count":215,"outputs":[]},{"cell_type":"code","source":["messages_silhouette_score(X, labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zy-pBbnYeaFT","executionInfo":{"status":"ok","timestamp":1663962877278,"user_tz":180,"elapsed":409,"user":{"displayName":"FRANCISCO HORTAL","userId":"12015705806958710339"}},"outputId":"6d59dbf0-c89e-46e8-91b8-790b65651f0e"},"execution_count":216,"outputs":[{"output_type":"stream","name":"stdout","text":["Silhouette score for 1000 is -0.8060321473722232\n"]}]},{"cell_type":"markdown","source":["Ahora realiza una busqueda de hiperparámetros para encontrar la configuración que retorne el mejor *silhouette_score*. Como mínimo debes probar todas las combinaciones posibles de los siguientes parámetros:\n","\n","*   ***Linkage***: centroid y single.\n","*   ***Distance***: euclidean y cosine."],"metadata":{"id":"g9TmIXKWYUty"}},{"cell_type":"markdown","source":["Obtenemos las variables para las 4 combinaciones y el score"],"metadata":{"id":"XeibX3bAsyfs"}},{"cell_type":"code","source":["# Centroid, Euclidean\n","clustering = AgglomerativeClustering(X = vectors, linkage=\"centroid\", distance=\"Euclidean\")\n","d_ce, target_ce = clustering.clusterize()\n","labels = target_ce.values\n","labels[labels==np.inf] = -1\n","labels = labels.astype(int)\n","messages_silhouette_score(X, labels)\n","\n","# Centroid, Cosine\n","clustering = AgglomerativeClustering(X = vectors, linkage=\"centroid\", distance=\"Cosine\")\n","d_cc, target_cc = clustering.clusterize()\n","labels_cc = target_cc.values\n","labels_cc[labels_cc==np.inf] = -1\n","labels_cc = labels_cc.astype(int)\n","messages_silhouette_score(X, labels_cc)\n","\n","# Single, Euclidean\n","clustering = AgglomerativeClustering(X = vectors, linkage=\"single\", distance=\"Euclidean\")\n","d_se, target_se = clustering.clusterize()\n","labels = target_se.values\n","labels[labels==np.inf] = -1\n","labels = labels.astype(int)\n","messages_silhouette_score(X, labels)\n","\n","# Single, Cosine\n","clustering = AgglomerativeClustering(X = vectors, linkage=\"single\", distance=\"Cosine\")\n","d_sc, target_sc = clustering.clusterize()\n","labels = target_sc.values\n","labels[labels==np.inf] = -1\n","labels = labels.astype(int)\n","messages_silhouette_score(X, labels)"],"metadata":{"id":"iCVqvki9YjAk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663963024994,"user_tz":180,"elapsed":147720,"user":{"displayName":"FRANCISCO HORTAL","userId":"12015705806958710339"}},"outputId":"d18fee8e-c251-4da2-ff87-19e5660967c0"},"execution_count":217,"outputs":[{"output_type":"stream","name":"stdout","text":["Silhouette score for 1000 is -0.8060321473722232\n","Silhouette score for 1000 is -0.7778580458732165\n","Silhouette score for 1000 is -0.8331226295828066\n","Silhouette score for 1000 is -0.8081993859490699\n"]}]},{"cell_type":"markdown","source":["Hecho esto, responde las siguientes preguntas. Debes fundamentar todas tus respuestas con los resultados obtenidos en la búsqueda de hiperparametros.\n","1.   ¿Cual configuración fue la mejor? \n","2.   ¿Que métrica de distancia da mejores resultados? (puedes comparar las métricas fijando un valor) \n","3.   ¿Que relación observas entre el método de enlace y la métrica de distancia utilizada? **Justifica**.\n"],"metadata":{"id":"RvxjmUzXYonw"}},{"cell_type":"markdown","source":["1.   Podemos ver que el Silhouette Score más cercano a 1 es el de la combinación centroide coseno, por lo que esta es la mejor combinación y la que obtiene los mejores clusters.\n","2.   La mejor métrica de distancias es la de Coseno en este caso, ya que comparando las combinaciones de coseno con las euclideanas, siempre coseno fue más cercano a 1.\n","3.   Se puede ver que en el caso de el uso de euclidean es 0.02709 mejor con centroide que con simple. En el caso de cosine es 0.03034 mejor con centroide que con simple. Con esto podemos decir que el método de enlace por centroides es mejor que simple y en un 0.03 aproximadamente.\n","\n"],"metadata":{"id":"0XTigRxMvEzx"}},{"cell_type":"markdown","source":["# 5. Visualización (1 punto)\n","\n","Los [dendrogramas](https://es.wikipedia.org/wiki/Dendrograma) son una forma muy útil de visualizar el funcionamiento de los algoritmos de *clustering* aglomerativo. Para completar esta sección debes generar un dendrograma a partir de tu mejor configuración de `AgglomerativeClustering`. Para esto debes utilizar la función `dendrogram` del módulo `cluster.hierarchy` de scipy.\n","\n","<br>\n","<center>\n","<img src=\"https://docs.scipy.org/doc/scipy/_images/scipy-cluster-hierarchy-dendrogram-1_00.png\" width=\"400\"/>\n","\n","Fuente: https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.dendrogram.html\n","\n","</center>\n","\n","NOTA: Debes investigar que formato tiene la matriz `Z` (*linkage matrix*) que recibe `dendrogram` y adaptar el output de tu algoritmo acordemente. Está estrictamente prohibido obtener `Z` a partir de la función `linkage` del módulo `cluster.hierarchy`. Puedes modificar la clase `AgglomerativeClustering` si lo consideras necesario."],"metadata":{"id":"WAcsZZ6-Y4b4"}},{"cell_type":"code","source":["from scipy.cluster.hierarchy import dendrogram"],"metadata":{"id":"zCOcDk_72OAj","executionInfo":{"status":"ok","timestamp":1663963025004,"user_tz":180,"elapsed":37,"user":{"displayName":"FRANCISCO HORTAL","userId":"12015705806958710339"}}},"execution_count":218,"outputs":[]},{"cell_type":"code","source":["Z = pd.DataFrame(X)\n","Z[1] = labels_cc"],"metadata":{"id":"9QLte42CZVCb","executionInfo":{"status":"ok","timestamp":1663963099348,"user_tz":180,"elapsed":294,"user":{"displayName":"FRANCISCO HORTAL","userId":"12015705806958710339"}}},"execution_count":224,"outputs":[]},{"cell_type":"code","source":["m_c = matriz_distancias_c(Z, Z)"],"metadata":{"id":"65NTyYVd42H-","executionInfo":{"status":"ok","timestamp":1663963025008,"user_tz":180,"elapsed":28,"user":{"displayName":"FRANCISCO HORTAL","userId":"12015705806958710339"}}},"execution_count":220,"outputs":[]},{"cell_type":"code","source":["Z = Z.values\n","Z = np.asmatrix(Z)\n","Z = Z.transpose"],"metadata":{"id":"Y8VOX1hY0KBn","executionInfo":{"status":"ok","timestamp":1663963100442,"user_tz":180,"elapsed":9,"user":{"displayName":"FRANCISCO HORTAL","userId":"12015705806958710339"}}},"execution_count":225,"outputs":[]},{"cell_type":"code","source":["dendogram(Z)"],"metadata":{"id":"TwqTc-pM7ceZ"},"execution_count":null,"outputs":[]}]}