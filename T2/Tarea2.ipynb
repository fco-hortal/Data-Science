{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YnDiLwUdS1Gu"
   },
   "source": [
    "Pontificia Universidad Católica de Chile <br>\n",
    "Departamento de Ciencia de la Computación <br>\n",
    "IIC2433 - Minería de Datos\n",
    "<br>\n",
    "\n",
    "<center>\n",
    "    <h2> Tarea 2 </h2>\n",
    "    <h1> Ham o spam  </h1>\n",
    "    <p>\n",
    "        Profesor Marcelo Mendoza<br>\n",
    "        Segundo Semestre 2022<br>    \n",
    "        Fecha de entrega: Viernes 23 de septiembre 22.00 horas\n",
    "    </p>\n",
    "    <br>\n",
    "</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hXr7-famVI0x"
   },
   "source": [
    "## Indicaciones\n",
    "\n",
    "Deberás entregar **SOLO** el archivo .ipynb en el buzón respectivo en canvas. \n",
    "\n",
    "**IMPORTANTE**: \n",
    "- Se te dará puntaje tanto por código como por la manera en la que respondas las preguntas planteadas. Es decir, si tienes un código perfecto pero este no es explicado o no se responden preguntas asociadas a este, no se tendrá el puntaje completo.\n",
    "- El notebook debe tener todas las celdas de código ejecutadas. Cualquier notebook que no las tenga no podrá ser corregido.\n",
    "- El carácter de esta tarea es **INDIVIDUAL**. Cualquier instancia de copia resultará en un 1,1 como nota de curso.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HEM29b-HVfIi"
   },
   "source": [
    "Utilizaremos una base de datos ubicada en Kaggle https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset que puedes encontrar igualmente en canvas como csv para descargar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ATIl8_5SZqH1"
   },
   "source": [
    "## Introducción\n",
    "\n",
    "Nadie es inmune a recibir mensajes de Movistar o Entel ofreciéndonos planes. Abrir un mensaje para encontrarse con una hermosa sorpresa: es spam. \n",
    "\n",
    "Este es un problema a nivel mundial, tanto así que se han armado bases de datos con diferentes mensajes de texto recibidos por persona y si son considerados como spam o no (si no son spam se refiere a los mensajes como ham).\n",
    "\n",
    "Utilizando la vectorización de frases y clusterizando estas, deberás predecir si esta es o no spam. Además, deberás obtener los índices de calidad de los clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HanOLeY9fjFV"
   },
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "IResCwZ4gp8H"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ahora debes reiniciar el entorno de ejecución y ejecutar a partir de la siguiente celda\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "clear_output()\n",
    "print('Ahora debes reiniciar el entorno de ejecución y ejecutar a partir de la siguiente celda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6p4Ad0YDg0iH"
   },
   "source": [
    "## 1. Importar librerías y descargar dataset\n",
    "En esta tarea trabajaremos con la librería `spacy` y el pipeline `en_core_web_lg` el cual pesa más de 500 MB y contiene un vocabulario en inglés de más de medio millón de palabras. Cada una de estas palabras es representable a partir de un vector de 300 dimensiones que nos ayudarán en la tarea. Revisa la [documentación](https://spacy.io/api) documentación de la librería para saber más."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "RPg3sNQOVH_5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B25-rStYiGjf"
   },
   "source": [
    "### Leer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "MIX2mob7S0HQ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        v1                                                 v2 Unnamed: 2  \\\n",
       "0      ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1      ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3      ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "...    ...                                                ...        ...   \n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...        NaN   \n",
       "5568   ham              Will Ì_ b going to esplanade fr home?        NaN   \n",
       "5569   ham  Pity, * was in mood for that. So...any other s...        NaN   \n",
       "5570   ham  The guy did some bitching but I acted like i'd...        NaN   \n",
       "5571   ham                         Rofl. Its true to its name        NaN   \n",
       "\n",
       "     Unnamed: 3 Unnamed: 4  \n",
       "0           NaN        NaN  \n",
       "1           NaN        NaN  \n",
       "2           NaN        NaN  \n",
       "3           NaN        NaN  \n",
       "4           NaN        NaN  \n",
       "...         ...        ...  \n",
       "5567        NaN        NaN  \n",
       "5568        NaN        NaN  \n",
       "5569        NaN        NaN  \n",
       "5570        NaN        NaN  \n",
       "5571        NaN        NaN  \n",
       "\n",
       "[5572 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'spam.csv'\n",
    "df = pd.read_csv(url, index_col=0, encoding=\"ISO-8859-1\")\n",
    "df.reset_index(inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HTPNejOsifeV"
   },
   "source": [
    "## 2. Procesamiento de los datos (1 punto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1q04il_DkYTx"
   },
   "source": [
    "### 2.1 Eliminación de datos\n",
    "Solamente analizaremos las columnas de si es o no spam y cuál es el mensaje. Elimina las columnas restantes y preprocesa las filas eliminando los valores nulos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero eliminamos las columnas Unnamed: 2, Unnamed: 3 y Unnamed 4. Luego eliminaremos los valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm gonna be home soon and i don't want to tal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>spam</td>\n",
       "      <td>SIX chances to win CASH! From 100 to 20,000 po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>spam</td>\n",
       "      <td>URGENT! You have won a 1 week FREE membership ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>spam</td>\n",
       "      <td>XXXMobileMovieClub: To use your credit, click ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ham</td>\n",
       "      <td>Oh k...i'm watching here:)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ham</td>\n",
       "      <td>Eh u remember how 2 spell his name... Yes i di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ham</td>\n",
       "      <td>Fine if thatåÕs the way u feel. ThatåÕs the wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>spam</td>\n",
       "      <td>England v Macedonia - dont miss the goals/team...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ham</td>\n",
       "      <td>Is that seriously how you spell his name?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ham</td>\n",
       "      <td>IÛ÷m going to try for 2 months ha ha only joking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ham</td>\n",
       "      <td>So Ì_ pay first lar... Then when is da stock c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ham</td>\n",
       "      <td>Aft i finish my lunch then i go str down lor. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ffffffffff. Alright no way I can meet up with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ham</td>\n",
       "      <td>Just forced myself to eat a slice. I'm really ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ham</td>\n",
       "      <td>Lol your always so convincing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ham</td>\n",
       "      <td>Did you catch the bus ? Are you frying an egg ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm back &amp;amp; we're packing the car now, I'll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ahhh. Work. I vaguely remember that! What does...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ham</td>\n",
       "      <td>Wait that's still not all that clear, were you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yeah he got in at 2 and was v apologetic. n ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ham</td>\n",
       "      <td>K tell me anything about you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ham</td>\n",
       "      <td>For fear of fainting with the of all that hous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>spam</td>\n",
       "      <td>Thanks for your subscription to Ringtone UK yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yup... Ok i go home look at the timings then i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ham</td>\n",
       "      <td>Oops, I'll let you know when my roommate's done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ham</td>\n",
       "      <td>I see the letter B on my car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ham</td>\n",
       "      <td>Anything lor... U decide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hello! How's you and how did saturday go? I wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pls go ahead with watts. I just wanted to be s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ham</td>\n",
       "      <td>Did I forget to tell you ? I want you , I need...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>spam</td>\n",
       "      <td>07732584351 - Rodger Burns - MSG = We tried to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>ham</td>\n",
       "      <td>WHO ARE YOU SEEING?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>ham</td>\n",
       "      <td>Great! I hope you like your man well endowed. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>ham</td>\n",
       "      <td>No calls..messages..missed calls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>ham</td>\n",
       "      <td>Didn't you get hep b immunisation in nigeria.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>ham</td>\n",
       "      <td>Fair enough, anything going on?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yeah hopefully, if tyler can't do it I could m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>ham</td>\n",
       "      <td>U don't know how stubborn I am. I didn't even ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      v1                                                 v2\n",
       "0    ham  Go until jurong point, crazy.. Available only ...\n",
       "1    ham                      Ok lar... Joking wif u oni...\n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    ham  U dun say so early hor... U c already then say...\n",
       "4    ham  Nah I don't think he goes to usf, he lives aro...\n",
       "5   spam  FreeMsg Hey there darling it's been 3 week's n...\n",
       "6    ham  Even my brother is not like to speak with me. ...\n",
       "7    ham  As per your request 'Melle Melle (Oru Minnamin...\n",
       "8   spam  WINNER!! As a valued network customer you have...\n",
       "9   spam  Had your mobile 11 months or more? U R entitle...\n",
       "10   ham  I'm gonna be home soon and i don't want to tal...\n",
       "11  spam  SIX chances to win CASH! From 100 to 20,000 po...\n",
       "12  spam  URGENT! You have won a 1 week FREE membership ...\n",
       "13   ham  I've been searching for the right words to tha...\n",
       "14   ham                I HAVE A DATE ON SUNDAY WITH WILL!!\n",
       "15  spam  XXXMobileMovieClub: To use your credit, click ...\n",
       "16   ham                         Oh k...i'm watching here:)\n",
       "17   ham  Eh u remember how 2 spell his name... Yes i di...\n",
       "18   ham  Fine if thatåÕs the way u feel. ThatåÕs the wa...\n",
       "19  spam  England v Macedonia - dont miss the goals/team...\n",
       "20   ham          Is that seriously how you spell his name?\n",
       "21   ham  IÛ÷m going to try for 2 months ha ha only joking\n",
       "22   ham  So Ì_ pay first lar... Then when is da stock c...\n",
       "23   ham  Aft i finish my lunch then i go str down lor. ...\n",
       "24   ham  Ffffffffff. Alright no way I can meet up with ...\n",
       "25   ham  Just forced myself to eat a slice. I'm really ...\n",
       "26   ham                     Lol your always so convincing.\n",
       "27   ham  Did you catch the bus ? Are you frying an egg ...\n",
       "28   ham  I'm back &amp; we're packing the car now, I'll...\n",
       "29   ham  Ahhh. Work. I vaguely remember that! What does...\n",
       "30   ham  Wait that's still not all that clear, were you...\n",
       "31   ham  Yeah he got in at 2 and was v apologetic. n ha...\n",
       "32   ham                      K tell me anything about you.\n",
       "33   ham  For fear of fainting with the of all that hous...\n",
       "34  spam  Thanks for your subscription to Ringtone UK yo...\n",
       "35   ham  Yup... Ok i go home look at the timings then i...\n",
       "36   ham    Oops, I'll let you know when my roommate's done\n",
       "37   ham                       I see the letter B on my car\n",
       "38   ham                        Anything lor... U decide...\n",
       "39   ham  Hello! How's you and how did saturday go? I wa...\n",
       "40   ham  Pls go ahead with watts. I just wanted to be s...\n",
       "41   ham  Did I forget to tell you ? I want you , I need...\n",
       "42  spam  07732584351 - Rodger Burns - MSG = We tried to...\n",
       "43   ham                                WHO ARE YOU SEEING?\n",
       "44   ham  Great! I hope you like your man well endowed. ...\n",
       "45   ham                   No calls..messages..missed calls\n",
       "46   ham      Didn't you get hep b immunisation in nigeria.\n",
       "47   ham                    Fair enough, anything going on?\n",
       "48   ham  Yeah hopefully, if tyler can't do it I could m...\n",
       "49   ham  U don't know how stubborn I am. I didn't even ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1)\n",
    "df = df.dropna()\n",
    "df.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JRc8KlOrKWya"
   },
   "source": [
    "### 2.2 Preprocesamiento de oraciones\n",
    "\n",
    "Acá te damos el código para preprocesar un texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "nrEFtXFTlLHY"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this the time have try contact'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "all_stopwords = nlp.Defaults.stop_words\n",
    "\n",
    "def remove_punctuation(text):\n",
    "  text = [token for token in text if not token.is_punct]\n",
    "  return text\n",
    "\n",
    "def remove_stopwords(words):\n",
    "  words = [word for word in words if not word in all_stopwords]\n",
    "  return words\n",
    "\n",
    "def lemmatize(words):\n",
    "  words = [word.lemma_ for word in words]\n",
    "  return words\n",
    "\n",
    "def remove_non_alpha(words):\n",
    "  words = [word for word in words if word.isalpha()]\n",
    "  return words\n",
    "\n",
    "def lower(words):\n",
    "  words = [word.lower() for word in words]\n",
    "  return words\n",
    "\n",
    "def min_len(words, length=3):\n",
    "  words = [word for word in words if len(word)>=length]\n",
    "  return words\n",
    "\n",
    "def preprocess(text):\n",
    "\n",
    "  doc = nlp(text)\n",
    "  tokens = remove_punctuation(doc)\n",
    "  tokens = remove_stopwords(tokens)\n",
    "  tokens = lemmatize(tokens)\n",
    "  tokens = remove_non_alpha(tokens)\n",
    "  tokens = lower(tokens)\n",
    "  tokens = min_len(tokens, length=3)\n",
    "\n",
    "  return ' '.join(tokens).strip()\n",
    "\n",
    "# Este es un ejemplo para que veas si tu preprocesamiento funcionó.\n",
    "new_text = preprocess(\"This is the 2nd time we have tried 2 contact...\")\n",
    "new_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4aN3CB3ijwlB"
   },
   "source": [
    "Preprocesa todos los mensajes utilizando el método preprocess y guárdalos en un dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p = df['v2'].apply(func=preprocess)\n",
    "\n",
    "df_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_wga_PgMmMmr"
   },
   "source": [
    "### 2.3 Vectorizar oraciones\n",
    "En esta tarea, el vector de una oración será el promedio de los vectores de cada una de las palabras que fueron preprocesadas de la oración. La función presentada a continuación vectoriza una oración a partir de los vectores de las palabras.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z369fruNmVMF"
   },
   "outputs": [],
   "source": [
    "def sentence_vector(text):\n",
    "  text = nlp(text)\n",
    "  vectores = []\n",
    "  for t in text:\n",
    "    t_vector = t.vector\n",
    "    vectores.append(t_vector)\n",
    "  return np.array(vectores).sum(axis=0)/len(vectores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6aUAuR0_g195"
   },
   "source": [
    "### 2.4. Obtener matriz de distancias\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vbHlE8PjhKNg"
   },
   "source": [
    "Obtén una forma de calcular una matriz que por cada par distintos de oraciones contenga la distancia euclidiana y coseno entre los vectores que representan a cada una. \n",
    "\n",
    "Hint: el método pairwise_distances de sklearn realiza esta operación eficientemente y no genera problemas de RAM.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fBSyhBgshK4o"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "matriz = pairwise_distances(sentence_vector(df_p['v2']), sentence_vector(df_p['v2']), metric='euclidean')\n",
    "\n",
    "# Tu código aquí"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_v = []\n",
    "for i in df_p['v2']:\n",
    "    list_v.append(sentence_vector(i))\n",
    "    print(sentence_vector(i))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-NGGrYDXe_Vb"
   },
   "source": [
    "## 3. Clase AgglomerativeClustering (3 puntos)\n",
    "\n",
    "Esta clase debe implemetar el algoritmo de clustering jerárquico aglomerativo. Para esto **debes** programar los siguientes métodos:\n",
    "\n",
    "\n",
    "### **\\_\\_init\\_\\_**\n",
    "Inicializa el algoritmo a partir de: la matriz `X` de los mensajes y la matriz de distancias. Considera además todas las variables que necesites a lo largo de la ejecución de tu algoritmo, se recomienda como mínimo:\n",
    "*   Un contador que indique el nivel actual de aglomeración.\n",
    "*   Un diccionario o lista que almacene los clusters en cada nivel de aglomeración. Inicialmente, en el nivel 0, existe un *cluster* por cada mensaje de `X`.\n",
    "*   La matriz de distancia entre los *clusters* donde el elemento `matriz[id1][id2]` corresponde a la distancia entre los clusters con identificadores `id1` e `id2` respectivamente. \n",
    "*   Una copia de la matriz original X.\n",
    "\n",
    "\n",
    "### **clusterize**\n",
    "Ejecuta el método next_level hasta que solo existan dos *clusters*.\n",
    "\n",
    "##### **next_level**\n",
    "Equivale a realizar un nivel de aglomeración del algoritmo. A modo general deben:\n",
    "1.   Obtener el par de *clusters* con menor distancia a partir de la matriz de distancias obtenida en 3.\n",
    "2.   Unir ambos *clusters*.\n",
    "3.   Guardar el nuevo conjunto de *clusters* correspondientes al nivel actual de aglomeración.\n",
    "4.   Actualizar la matriz de distancias según el nuevo conjunto de *clusters*.\n",
    "\n",
    "##### **update_matrix**\n",
    "Actualiza la matriz de distancias dado un nuevo *cluster*. La distancia entre *clusters* debe poder calcularse según los siguientes enlaces (`linkage`) vistos en clases:\n",
    "1.   **centroid**: distancia entre medias.\n",
    "2.   **single**: simple.\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "**NOTA**: puedes entregarle los argumentos que quieras a estos métodos y tambien crear otros métodos que consideres pertinentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zhMaokeoTulC"
   },
   "source": [
    "En base a lo visto en clases deberás implementar el algoritmo de clustering aglomerativo para agrupar los datos previamente preprocesados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nMvVAAalUpYb"
   },
   "outputs": [],
   "source": [
    "class AgglomerativeClustering:\n",
    "\n",
    "  def __init__(self, X, linkage=\"centroid\", distance=\"Euclidean\"):\n",
    "    # Vectores de cada pais.\n",
    "    self.X = X.copy()\n",
    "    # Linkage.\n",
    "    self.linkage = linkage\n",
    "    # Métrica de distancia.\n",
    "    self.distance = distance\n",
    "\n",
    "    # Matriz de distancias (obtén la matriz de distancias inicial)\n",
    "    # self.matrix = # \n",
    "\n",
    "    # Copia de la matriz de distancias original.\n",
    "    self.original_matrix = self.matrix.copy()\n",
    "\n",
    "\n",
    "  def clusterize(self):\n",
    "    pass\n",
    "\n",
    "  def next_level(self):\n",
    "    # Obtén el par de clusters con menor distancia de la matriz de distancias.\n",
    "    \n",
    "    # Crea un nuevo cluster a partir de los dos anteriores\n",
    "    \n",
    "    # El nuevo nivel tiene los clusters anteriores y la union de los dos clusters elegidos.\n",
    "  \n",
    "    # Elimina los dos clusters elegidos de la matriz de distancias.\n",
    "    \n",
    "    # Actualiza la matriz de distancias ingresando el nuevo cluster.\n",
    "\n",
    "    pass\n",
    "\n",
    "  \n",
    "  def update_matrix(self, cluster):\n",
    "\n",
    "    if self.linkage == \"centroid\":\n",
    "      pass\n",
    "\n",
    "    elif self.linkage == \"single\":\n",
    "      pass\n",
    "\n",
    "  def get_distance(self, vector1, vector2):\n",
    "    if self.distance == \"Euclidean\": \n",
    "      pass\n",
    "    \n",
    "    elif self.distance == \"Cosine\":\n",
    "      pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-6ALTMRzXWMB"
   },
   "source": [
    "Utiliza la clase para realizar la aglomeración con los datos preprocesados de spam:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HuhX_nSzXuUx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8HPYMJC5X9Vf"
   },
   "source": [
    "# 4. Comparación con distintos parámetros (1 punto)\n",
    "\n",
    "En esta parte deberás comparar distintas configuraciones de tu algoritmo de *clustering* y concluir cual de estas es la mejor.\n",
    "\n",
    "Una forma de comparar *clusters* es a partir de su *silhouette score*. Este mide cuán similar es un objeto a su propio *cluster* (cohesión) en comparación con otros *clusters* (separación). Completa el siguiente código utilizando la función `silhouette_score` de `sklearn.metrics`.\n",
    "\n",
    "NOTA: debes adaptar la estructura de clusters retornada por `AgglomerativeClustering` de tal forma que pueda ser utilizada como los `labels` que recibe `silhouette_score` ([documentación](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RD1tB3ZFYHLT"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "def messages_silhouette_score(X, clusters):\n",
    "  pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g9TmIXKWYUty"
   },
   "source": [
    "Ahora realiza una busqueda de hiperparámetros para encontrar la configuración que retorne el mejor *silhouette_score*. Como mínimo debes probar todas las combinaciones posibles de los siguientes parámetros:\n",
    "\n",
    "*   ***Linkage***: centroid y single.\n",
    "*   ***Distance***: euclidean y cosine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iCVqvki9YjAk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RvxjmUzXYonw"
   },
   "source": [
    "Hecho esto, responde las siguientes preguntas. Debes fundamentar todas tus respuestas con los resultados obtenidos en la búsqueda de hiperparametros.\n",
    "1.   ¿Cual configuración fue la mejor? \n",
    "2.   ¿Que métrica de distancia da mejores resultados? (puedes comparar las métricas fijando un valor) \n",
    "3.   ¿Que relación observas entre el método de enlace y la métrica de distancia utilizada? **Justifica**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WAcsZZ6-Y4b4"
   },
   "source": [
    "# 5. Visualización (1 punto)\n",
    "\n",
    "Los [dendrogramas](https://es.wikipedia.org/wiki/Dendrograma) son una forma muy útil de visualizar el funcionamiento de los algoritmos de *clustering* aglomerativo. Para completar esta sección debes generar un dendrograma a partir de tu mejor configuración de `AgglomerativeClustering`. Para esto debes utilizar la función `dendrogram` del módulo `cluster.hierarchy` de scipy.\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "<img src=\"https://docs.scipy.org/doc/scipy/_images/scipy-cluster-hierarchy-dendrogram-1_00.png\" width=\"400\"/>\n",
    "\n",
    "Fuente: https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.dendrogram.html\n",
    "\n",
    "</center>\n",
    "\n",
    "NOTA: Debes investigar que formato tiene la matriz `Z` (*linkage matrix*) que recibe `dendrogram` y adaptar el output de tu algoritmo acordemente. Está estrictamente prohibido obtener `Z` a partir de la función `linkage` del módulo `cluster.hierarchy`. Puedes modificar la clase `AgglomerativeClustering` si lo consideras necesario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9QLte42CZVCb"
   },
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
